{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "import exifread\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "tqdm.pandas(desc=\"progress-bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|██████████| 260/260 [00:04<00:00, 63.98it/s] \n",
      "progress-bar: 100%|██████████| 260/260 [00:00<00:00, 23550.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get mapping of old path and new paths for all files\n",
    "\n",
    "src_path=r'C:\\Users\\vigne\\Desktop\\Takeout'\n",
    "dst_path=r'C:\\Users\\vigne\\Pictures\\New Photos'\n",
    "formats = ['*.jpg','*.gif', '*.jpeg', '*.png','*.mp4','*.avi','*.3gp','*.mkv']\n",
    "df=pd.DataFrame(columns=['filename','year','month'])\n",
    "all_files = []\n",
    "for ext in formats:\n",
    "    all_files.extend(Path(src_path).rglob(ext))\n",
    "df['filename']=all_files\n",
    "\n",
    "def capturedate(filename):\n",
    "    with open(filename, 'rb') as image: # file path and name\n",
    "        try:\n",
    "            exif = exifread.process_file(image)\n",
    "            dt = str(exif['EXIF DateTimeOriginal'])\n",
    "            date=datetime.strptime(dt, \"%Y:%m:%d %H:%M:%S\")\n",
    "            return str(date.year),str(date.month).rjust(2, '0')\n",
    "        except Exception as e:\n",
    "            d=datetime.fromtimestamp(os.path.getmtime(filename))\n",
    "            return d.strftime('%Y'),d.strftime('%m')\n",
    "\n",
    "df[['year','month']]=df.progress_apply(lambda r: capturedate(r['filename']), axis=1, result_type=\"expand\")\n",
    "df['filename']=df['filename'].astype(str)\n",
    "def create_new_path(row):\n",
    "    #check file extension\n",
    "    videos=['.mp4','.avi','.3gp','.mkv']\n",
    "    fname=os.path.basename(row['filename'])\n",
    "    if(Path(fname).suffix.lower() in videos):\n",
    "        return os.path.join(dst_path,'Videos',row['year'],row['month'],fname)\n",
    "    elif('screenshot' in fname.lower()):\n",
    "        return os.path.join(dst_path,'Screenshot',row['year'],row['month'],fname)\n",
    "    elif('wa' in fname.lower()):\n",
    "        return os.path.join(dst_path,'Whatsapp',row['year'],row['month'],fname)\n",
    "    else:\n",
    "        return os.path.join(dst_path,row['year'],row['month'],fname)\n",
    "\n",
    "df['new_path']=df.progress_apply(lambda r: create_new_path(r), axis=1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|██████████| 260/260 [00:12<00:00, 20.81it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will copy 234/260 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create hash for new files and compare\n",
    "def create_hash(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        file_hash = hashlib.blake2s()\n",
    "        while chunk := f.read(8192):\n",
    "            file_hash.update(chunk)\n",
    "        return file_hash.hexdigest()\n",
    "\n",
    "df['hash']=df.progress_apply(lambda r: create_hash(r['filename']), axis=1)\n",
    "pq_file=os.path.join(dst_path,'photo_info.pq')\n",
    "destination_content=pd.read_parquet(pq_file)\n",
    "orignal_len=len(df)\n",
    "df=df[~df['hash'].isin(destination_content['hash'])]\n",
    "print(f'will copy {df.shape[0]}/{orignal_len} files')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:09<00:00, 25.77it/s] \n"
     ]
    }
   ],
   "source": [
    "# copy files to new path\n",
    "\n",
    "with tqdm(total=df.shape[0]) as pbar: \n",
    "    for i,r in df.iterrows():\n",
    "        pbar.update(1)\n",
    "        os.makedirs(os.path.dirname(r['new_path']), exist_ok=True)\n",
    "        shutil.copy(r['filename'], r[\"new_path\"])\n",
    "\n",
    "#writeback new hashes\n",
    "for i,r in df.iterrows():\n",
    "    destination_content=destination_content.append({'filename':str(r['new_path']).replace(dst_path,''),'hash':r['hash']},ignore_index=True)\n",
    "destination_content.to_parquet(pq_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities and for first time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates :  756\n"
     ]
    }
   ],
   "source": [
    "# remove duplicates within folder\n",
    "folder=r'C:\\Users\\vigne\\Pictures\\New Photos'\n",
    "contents=pd.read_parquet(os.path.join(folder,'photo_info.pq'))\n",
    "duplicated_files=contents[contents['hash'].duplicated()]['filename'].to_list()\n",
    "print(\"Duplicates : \",len(duplicated_files))\n",
    "for i in duplicated_files:\n",
    "    os.remove(os.path.join(folder,i.strip('\\\\')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this only if you creating a new source folder. else use above code\n",
    "# after this run the hexdigest code (below) for that folder\n",
    "# copy files to new path\n",
    "\n",
    "with tqdm(total=df.shape[0]) as pbar: \n",
    "    for i,r in df.iterrows():\n",
    "        pbar.update(1)\n",
    "        os.makedirs(os.path.dirname(r['new_path']), exist_ok=True)\n",
    "        shutil.copy(r['filename'], r[\"new_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9307/9307 [01:51<00:00, 83.36it/s] \n"
     ]
    }
   ],
   "source": [
    "# Generate hash for all files in a folder\n",
    "# only during the first time\n",
    "\n",
    "hash_df=pd.DataFrame(columns=['filename','hash'])\n",
    "path=r'C:\\Users\\vigne\\Pictures\\New Photos'\n",
    "with tqdm(total=len(list(Path(path).rglob('*.*')))) as pbar: \n",
    "    for file in Path(path).rglob('*.*'):\n",
    "        with open(file, \"rb\") as f:\n",
    "            file_hash = hashlib.blake2s()\n",
    "            while chunk := f.read(8192):\n",
    "                file_hash.update(chunk)\n",
    "            hash_df=hash_df.append({'filename':str(file).replace(path,''),'hash':file_hash.hexdigest()},ignore_index=True)\n",
    "            pbar.update(1)\n",
    "\n",
    "hash_df.to_parquet(os.path.join(path,'photo_info.pq'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "44f587ad27c9c33235f69cd7082f684c5c80fc9b0fb7f82fc06c5632d2d70575"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
